Data Analytics




                 SESSION 23:
                  Assignment 1




                                 1
Data Analytics


Table of Contents
1.Introduction ............................................................................................................................................... 3
2.Objective .................................................................................................................................................... 3
3.Prerequisites .............................................................................................................................................. 3
4.Associated Data Files ................................................................................................................................. 3
5.Problem Statement .................................................................................................................................... 3
6.Expected Output ........................................................................................................................................ 3
7.Approximate Time to Complete Task ........................................................................................................ 3




                                                                                                                                                               2
Data Analytics




1. Introduction
This assignment will help you understand the concepts learnt in the session.

2. Objective
This assignment will test your skills using R.

3. Prerequisites
Not applicable.

4. Associated Data Files
Not applicable.

5. Problem Statement
   1. Perform the below given activities:
   a. Take Apple Stock Prices from Yahoo Finance for last 90 days
   AAPL.csv file path: 
        DATA-ANALYTICS-WITH-R-EXCEL-TABLEAU_Session23Assignment23.1/AAPL.csv
      
   b. Predict the Stock closing prices for next 15 days.
   c. Submit your accuracy
   d. After 15 days again collect the data and compare with your forecast

Answer:
> setwd("D:/ACADGILD/Excel files")
> library(readr)
> AAPL <- read.csv("AAPL.csv")
> AAPL <- read.csv("D:/ACADGILD/Excel files/AAPL.csv")
>   View(AAPL)
> View(AAPLMay10toAug102018)
> df<-AAPL
> head(df)
        Date   Open   High    Low  Close Adj.Close   Volume
1 2018-12-06 171.76 174.78 170.42 174.72    174.72 43098400
2 2018-12-07 173.49 174.49 168.30 168.49    168.49 42281600
3 2018-12-10 165.00 170.09 163.33 169.60    169.60 62026000
4 2018-12-11 171.66 171.79 167.00 168.63    168.63 47281700
5 2018-12-12 170.40 171.92 169.02 169.10    169.10 35627700
6 2018-12-13 170.49 172.57 169.55 170.95    170.95 31898600
> str(df)
'data.frame':	20 obs. of  7 variables:
 $ Date     : Factor w/ 20 levels "2018-12-06","2018-12-07",..: 1 2 3 4 5 6 7 8 9 10 ...
 $ Open     : num  172 173 165 172 170 ...
 $ High     : num  175 174 170 172 172 ...
 $ Low      : num  170 168 163 167 169 ...
 $ Close    : num  175 168 170 169 169 ...
 $ Adj.Close: num  175 168 170 169 169 ...
 $ Volume   : int  43098400 42281600 62026000 47281700 35627700 31898600 40703700 44287900 33841500 49047300 ...
> new_date <- as.Date(df$Date)
> new_date
 [1] "2018-12-06" "2018-12-07" "2018-12-10" "2018-12-11" "2018-12-12" "2018-12-13" "2018-12-14" "2018-12-17" "2018-12-18"
[10] "2018-12-19" "2018-12-20" "2018-12-21" "2018-12-24" "2018-12-26" "2018-12-27" "2018-12-28" "2018-12-31" "2019-01-02"
[19] "2019-01-03" "2019-01-04"
> str(df)
'data.frame':	20 obs. of  7 variables:
 $ Date     : Factor w/ 20 levels "2018-12-06","2018-12-07",..: 1 2 3 4 5 6 7 8 9 10 ...
 $ Open     : num  172 173 165 172 170 ...
 $ High     : num  175 174 170 172 172 ...
 $ Low      : num  170 168 163 167 169 ...
 $ Close    : num  175 168 170 169 169 ...
 $ Adj.Close: num  175 168 170 169 169 ...
 $ Volume   : int  43098400 42281600 62026000 47281700 35627700 31898600 40703700 44287900 33841500 49047300 ...
> format(new_date,format="%B %d %Y")
 [1] "December 06 2018" "December 07 2018" "December 10 2018" "December 11 2018" "December 12 2018" "December 13 2018"
 [7] "December 14 2018" "December 17 2018" "December 18 2018" "December 19 2018" "December 20 2018" "December 21 2018"
[13] "December 24 2018" "December 26 2018" "December 27 2018" "December 28 2018" "December 31 2018" "January 02 2019" 
[19] "January 03 2019"  "January 04 2019" 
> 
# %d - day as number 1-31
# %a - weekday such as Mon
# %A- complete day name ex.Monday
# %m - month as a number
# %b - short form of month Jan, Feb
# %B - full form of month, January
# %y - two digit year
# %Y- four digit year

> data = ts(df$Close,frequency =12)
> plot(data,main="Monthly Closing Prices")
plot path: 
        DATA-ANALYTICS-WITH-R-EXCEL-TABLEAU_Session23Assignment23.1/23.1 Monthly Closing Prices.png

# Additive Time Series
# Trend + Seasonality+ Cyclicity+ error 
# Multiplicative Time Series
## Trend * Seasonality * Cyclicity * error

# additive model is easy to explain, easy to forecast and interpret
# multiplicate models can be converted to additive models using log of the time series

> log(data)
       Jan      Feb      Mar      Apr      May      Jun      Jul      Aug      Sep      Oct      Nov      Dec
1 5.163185 5.126876 5.133443 5.127707 5.130490 5.141371 5.108850 5.099501 5.112409 5.080721 5.055162 5.015490
2 4.989275 5.057328 5.050817 5.051329 5.060948 5.062089 4.957164 4.998967                                    

# assumption for time series forecst:
#1- the time series should be stationary
# Identify the stationarity of a time series
#1- mean value of the time series is constant over time, the trend should not be present in the series
#2- the variance does not increase over time
#3- the seasonality impact is minimal, deseasonalization of the time series data

> decompose(data) # default method is additive
> decompose(data, type='multi')
> par(mfrow=c(1,2))
> plot(decompose(data, type='multi'))
> library(forecast)

> seasonplot(data)

> lag(data,10)
plot path: 
        DATA-ANALYTICS-WITH-R-EXCEL-TABLEAU_Session23Assignment23.1/23.1 lag plot.png
      
 # Calculation of Autocorrelation and Partial Autocorrelation
> data
     Jan    Feb    Mar    Apr    May    Jun    Jul    Aug    Sep    Oct    Nov    Dec
1 174.72 168.49 169.60 168.63 169.10 170.95 165.48 163.94 166.07 160.89 156.83 150.73
2 146.83 157.17 156.15 156.23 157.74 157.92 142.19 148.26                            
> ac<-acf(data)
series data plot path:
        DATA-ANALYTICS-WITH-R-EXCEL-TABLEAU_Session23Assignment23.1/23.1 Series data.png
      
> ac$acf
, , 1

             [,1]
 [1,]  1.00000000
 [2,]  0.69378791
 [3,]  0.46606515
 [4,]  0.38610867
 [5,]  0.28958535
 [6,]  0.20216548
 [7,]  0.15753235
 [8,]  0.09118868
 [9,] -0.03291989
[10,] -0.20257529
[11,] -0.32684466
[12,] -0.34668112
[13,] -0.31716513
[14,] -0.27578530

# data time series may not have stationarity
> pac<-pacf(data)
series data2 plot path :
        DATA-ANALYTICS-WITH-R-EXCEL-TABLEAU_Session23Assignment23.1/23.1 series data 2.png
      
> pac$acf
, , 1

              [,1]
 [1,]  0.693787905
 [2,] -0.029453888
 [3,]  0.142161202
 [4,] -0.049985487
 [5,] -0.006205465
 [6,]  0.014823652
 [7,] -0.062772760
 [8,] -0.153988792
 [9,] -0.239068499
[10,] -0.159452550
[11,] -0.014763309
[12,]  0.029208504
[13,]  0.047058068

>  

# looking at the ACF and PACF graph we can conclude that the time 
# series is not stationary
> model <- lm(data~c(1:length(data)))
> summary(model)

Call:
lm(formula = data ~ c(1:length(data)))

Residuals:
     Min       1Q   Median       3Q      Max 
-10.3044  -1.1641   0.4001   2.1998   7.3088 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       174.0948     2.1265  81.870  < 2e-16 ***
c(1:length(data))  -1.3046     0.1775  -7.349 8.02e-07 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 4.578 on 18 degrees of freedom
Multiple R-squared:  0.7501,	Adjusted R-squared:  0.7362 
F-statistic: 54.01 on 1 and 18 DF,  p-value: 8.024e-07

> plot(resid(model),type='l')
plot path: DATA-ANALYTICS-WITH-R-EXCEL-TABLEAU_Session23Assignment23.1/23.1 Residual.png
      
# the series is not stationary
# deseasonalize the time series

> tbl <- stl(data,'periodic')
> stab<-seasadj(tbl)
> seasonplot(stab,12)

# statistically we need to test out if the series is stationary or not
# Augmented Dickey Fuller Test

> library(tseries)
> adf.test(data)

# if the p-value is less than 0.05, then the time series is stationary, else not

# Time Series Forecasting Models

# Simple Exponential Smoothing
# Double Expo. Smoothing
# Tripple Expo. Smoothing 
# AR-I-MA model

#PACF- p 
#diff - d
#ACF- q

> model2<-auto.arima(data)
> accuracy(model2)
> plot(forecast(model2,h=12))

> adf.test(diff(data))

> plot(diff(data))

  Plot path: DATA-ANALYTICS-WITH-R-EXCEL-TABLEAU_Session23Assignment23.1/23.1 Residual vs Diff data.png
  > diff(data,differences = 3)
         Jan        Feb        Mar        Apr        May        Jun        Jul        Aug        Sep        Oct        Nov
1                                   -9.419999   3.520004  -0.060012  -8.699982  11.249999  -0.260008 -10.980012   8.430024
2   4.240021  12.039978 -25.599990  12.460006   0.330001  -2.760023 -14.579973  37.709978                                 
         Dec
1  -3.160020
2           
> 

> #running a model on diff data
> model3<-auto.arima(diff(data))

> accuracy(model3)
> ##                     ME     RMSE      MAE MPE MAPE      MASE      ACF1
> ## Training set 0.2732813 2.188771 1.472657 100  100 0.7590256 0.1695623
> acf(diff(data))
> pacf(diff(data))
plot path: DATA-ANALYTICS-WITH-R-EXCEL-TABLEAU_Session23Assignment23.1/23.1 ACF and Partial ACF.png

 > #taking random order
> model4 <- Arima(diff(data),order=c(4,0,5))

> model4
> accuracy(model4)
> model5 <- Arima(diff(data),order=c(4,0,4))
> model5
> accuracy(model5)
> model6<-Arima(data,order=c(3,0,5))
> model6
> accuracy(model6)
> model7<-Arima(diff(data),order=c(4,0,4))
> model7
> accuracy(model7)
> model8<-Arima(diff(data),order=c(0,0,1))
> model8
> accuracy(model8)
> model9<-Arima(diff(data),order=c(1,0,0))
> model9
> accuracy(model9)
> model10<-Arima(diff(data),order=c(1,0,1))
> model10
> accuracy(model10)
> model11<-Arima(diff(data),order=c(1,0,2))
> model11
> accuracy(model11)
> model12<-Arima(diff(data),order=c(1,1,3))
> model12
> accuracy(model12)
> # MAPE = mean absolute percentage error (should be < 10%) for a good model
> par(mfrow=c(1,2))
> plot(forecast(model5,h=12))
> plot(log(data))

> # if series is stationary then use simple exponential smoothing model
> model4<-HoltWinters(data,beta = F, gamma = F)
> summary(model4)
             Length Class  Mode     
fitted       38     mts    numeric  
x            20     ts     numeric  
alpha         1     -none- numeric  
beta          1     -none- logical  
gamma         1     -none- logical  
coefficients  1     -none- numeric  
seasonal      1     -none- character
SSE           1     -none- numeric  
call          4     -none- call     
> model4
Holt-Winters exponential smoothing without trend and without seasonal component.

Call:
HoltWinters(x = data, beta = F, gamma = F)

Smoothing parameters:
 alpha: 0.7802498
 beta : FALSE
 gamma: FALSE

Coefficients:
      [,1]
a 147.6801
> library(forecast)

> plot(forecast(model4,12))

> # if series is not stationary and only trend component is present, then use double exponential smoothing model
> model5<-HoltWinters(data,gamma = F)
> summary(model5)
             Length Class  Mode     
fitted       54     mts    numeric  
x            20     ts     numeric  
alpha         1     -none- numeric  
beta          1     -none- numeric  
gamma         1     -none- logical  
coefficients  2     -none- numeric  
seasonal      1     -none- character
SSE           1     -none- numeric  
call          3     -none- call     
> model5
Holt-Winters exponential smoothing with trend and without seasonal component.

Call:
HoltWinters(x = data, gamma = F)

Smoothing parameters:
 alpha: 0.8597559
 beta : 0.1832164
 gamma: FALSE

Coefficients:
        [,1]
a 147.342315
b  -1.602722

> plot(forecast(model5,12))
> plot(log(data))


> # Holt Winters Exponential Smoothing Model
> # if series is not stationary and trend, seasonality component is present, then use tripple exponential smoothing model
> model6<-HoltWinters(data)

> summary(model6)
> model6

> plot(log(data))
> plot(forecast(model6,12))
> # MAPE
> # Automatic Exponential Smoothing Model
> model7<-ets(data)
> summary(model7)
> accuracy(model7)
> plot(log(data))
> plot(forecast(model7,12))
> 
                                                                               3
Data Analytics

6. Expected Output
N/A

7. Approximate Time to Complete Task

30 mins.




                                       4

